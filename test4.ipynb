{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d981edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:408: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 390 training sequences\n",
      "Training samples: 1947\n",
      "Model parameters: 2,768,185\n",
      "Epoch 1/100: New best model found with loss: 3.5436. Saving checkpoint...\n",
      "Epoch 1/100, Loss: 3.5436, LR: 0.000200\n",
      "Epoch 2/100: New best model found with loss: 3.2496. Saving checkpoint...\n",
      "Epoch 3/100: New best model found with loss: 2.9594. Saving checkpoint...\n",
      "Epoch 4/100: New best model found with loss: 2.6776. Saving checkpoint...\n",
      "Epoch 5/100: New best model found with loss: 2.5002. Saving checkpoint...\n",
      "Epoch 6/100: New best model found with loss: 2.3041. Saving checkpoint...\n",
      "Epoch 6/100, Loss: 2.3041, LR: 0.000200\n",
      "Epoch 7/100: New best model found with loss: 2.1845. Saving checkpoint...\n",
      "Epoch 8/100: New best model found with loss: 2.0165. Saving checkpoint...\n",
      "Epoch 9/100: New best model found with loss: 1.9151. Saving checkpoint...\n",
      "Epoch 10/100: New best model found with loss: 1.7832. Saving checkpoint...\n",
      "Epoch 11/100: New best model found with loss: 1.6676. Saving checkpoint...\n",
      "Epoch 11/100, Loss: 1.6676, LR: 0.000200\n",
      "Epoch 12/100: New best model found with loss: 1.5584. Saving checkpoint...\n",
      "Epoch 13/100: New best model found with loss: 1.4727. Saving checkpoint...\n",
      "Epoch 14/100: New best model found with loss: 1.3723. Saving checkpoint...\n",
      "Epoch 15/100: New best model found with loss: 1.3064. Saving checkpoint...\n",
      "Epoch 16/100: New best model found with loss: 1.2195. Saving checkpoint...\n",
      "Epoch 16/100, Loss: 1.2195, LR: 0.000200\n",
      "Epoch 17/100: New best model found with loss: 1.1376. Saving checkpoint...\n",
      "Epoch 18/100: New best model found with loss: 1.0698. Saving checkpoint...\n",
      "Epoch 19/100: New best model found with loss: 1.0616. Saving checkpoint...\n",
      "Epoch 20/100: New best model found with loss: 1.0034. Saving checkpoint...\n",
      "Epoch 21/100: New best model found with loss: 0.9367. Saving checkpoint...\n",
      "Epoch 21/100, Loss: 0.9367, LR: 0.000200\n",
      "Epoch 22/100: New best model found with loss: 0.9084. Saving checkpoint...\n",
      "Epoch 23/100: New best model found with loss: 0.8792. Saving checkpoint...\n",
      "Epoch 24/100: New best model found with loss: 0.8630. Saving checkpoint...\n",
      "Epoch 25/100: New best model found with loss: 0.8511. Saving checkpoint...\n",
      "Epoch 26/100: New best model found with loss: 0.8150. Saving checkpoint...\n",
      "Epoch 26/100, Loss: 0.8150, LR: 0.000200\n",
      "Epoch 28/100: New best model found with loss: 0.7930. Saving checkpoint...\n",
      "Epoch 29/100: New best model found with loss: 0.7827. Saving checkpoint...\n",
      "Epoch 30/100: New best model found with loss: 0.7733. Saving checkpoint...\n",
      "Epoch 31/100: New best model found with loss: 0.7355. Saving checkpoint...\n",
      "Epoch 31/100, Loss: 0.7355, LR: 0.000200\n",
      "Epoch 33/100: New best model found with loss: 0.7088. Saving checkpoint...\n",
      "Epoch 36/100: New best model found with loss: 0.7032. Saving checkpoint...\n",
      "Epoch 36/100, Loss: 0.7032, LR: 0.000200\n",
      "Epoch 37/100: New best model found with loss: 0.6877. Saving checkpoint...\n",
      "Epoch 38/100: New best model found with loss: 0.6818. Saving checkpoint...\n",
      "Epoch 40/100: New best model found with loss: 0.6775. Saving checkpoint...\n",
      "Epoch 41/100: New best model found with loss: 0.6744. Saving checkpoint...\n",
      "Epoch 41/100, Loss: 0.6744, LR: 0.000200\n",
      "Epoch 42/100: New best model found with loss: 0.6524. Saving checkpoint...\n",
      "Epoch 45/100: New best model found with loss: 0.6416. Saving checkpoint...\n",
      "Epoch 46/100: New best model found with loss: 0.6391. Saving checkpoint...\n",
      "Epoch 46/100, Loss: 0.6391, LR: 0.000200\n",
      "Epoch 48/100: New best model found with loss: 0.6390. Saving checkpoint...\n",
      "Epoch 51/100: New best model found with loss: 0.6341. Saving checkpoint...\n",
      "Epoch 51/100, Loss: 0.6341, LR: 0.000200\n",
      "Epoch 52/100: New best model found with loss: 0.6162. Saving checkpoint...\n",
      "Epoch 55/100: New best model found with loss: 0.6096. Saving checkpoint...\n",
      "Epoch 56/100, Loss: 0.6171, LR: 0.000200\n",
      "Epoch 57/100: New best model found with loss: 0.6076. Saving checkpoint...\n",
      "Epoch 58/100: New best model found with loss: 0.6060. Saving checkpoint...\n",
      "Epoch 59/100: New best model found with loss: 0.6038. Saving checkpoint...\n",
      "Epoch 60/100: New best model found with loss: 0.6024. Saving checkpoint...\n",
      "Epoch 61/100: New best model found with loss: 0.5961. Saving checkpoint...\n",
      "Epoch 61/100, Loss: 0.5961, LR: 0.000200\n",
      "Epoch 63/100: New best model found with loss: 0.5890. Saving checkpoint...\n",
      "Epoch 64/100: New best model found with loss: 0.5867. Saving checkpoint...\n",
      "Epoch 65/100: New best model found with loss: 0.5832. Saving checkpoint...\n",
      "Epoch 66/100, Loss: 0.6056, LR: 0.000200\n",
      "Epoch 67/100: New best model found with loss: 0.5781. Saving checkpoint...\n",
      "Epoch 69/100: New best model found with loss: 0.5681. Saving checkpoint...\n",
      "Epoch 71/100, Loss: 0.5746, LR: 0.000200\n",
      "Epoch 75/100: New best model found with loss: 0.5650. Saving checkpoint...\n",
      "Epoch 76/100: New best model found with loss: 0.5554. Saving checkpoint...\n",
      "Epoch 76/100, Loss: 0.5554, LR: 0.000200\n",
      "Epoch 77/100: New best model found with loss: 0.5549. Saving checkpoint...\n",
      "Epoch 81/100, Loss: 0.5719, LR: 0.000200\n",
      "Epoch 82/100: New best model found with loss: 0.5533. Saving checkpoint...\n",
      "Epoch 85/100: New best model found with loss: 0.5485. Saving checkpoint...\n",
      "Epoch 86/100: New best model found with loss: 0.5449. Saving checkpoint...\n",
      "Epoch 86/100, Loss: 0.5449, LR: 0.000200\n",
      "Epoch 88/100: New best model found with loss: 0.5446. Saving checkpoint...\n",
      "Epoch 90/100: New best model found with loss: 0.5394. Saving checkpoint...\n",
      "Epoch 91/100, Loss: 0.5527, LR: 0.000200\n",
      "Epoch 95/100: New best model found with loss: 0.5271. Saving checkpoint...\n",
      "Epoch 96/100, Loss: 0.5410, LR: 0.000200\n",
      "Test Accuracy: 0.071\n",
      "\n",
      "=== Prediction Examples ===\n",
      "History: ['select', 'copy']\n",
      "  1. paste (prob: 0.987, conf: 0.986)\n",
      "  2. indent (prob: 0.002, conf: 0.986)\n",
      "  3. insert_shape (prob: 0.002, conf: 0.986)\n",
      "\n",
      "History: ['cut', 'paste']\n",
      "  1. bold (prob: 0.959, conf: 0.967)\n",
      "  2. cut (prob: 0.023, conf: 0.967)\n",
      "  3. italic (prob: 0.004, conf: 0.967)\n",
      "\n",
      "History: ['select', 'delete']\n",
      "  1. select (prob: 0.220, conf: 0.995)\n",
      "  2. paste (prob: 0.213, conf: 0.995)\n",
      "  3. web_layout (prob: 0.156, conf: 0.995)\n",
      "\n",
      "History: ['undo', 'undo']\n",
      "  1. cut (prob: 0.269, conf: 0.636)\n",
      "  2. redo (prob: 0.213, conf: 0.636)\n",
      "  3. delete (prob: 0.092, conf: 0.636)\n",
      "\n",
      "History: ['select', 'bold']\n",
      "  1. italic (prob: 0.970, conf: 0.961)\n",
      "  2. underline (prob: 0.007, conf: 0.961)\n",
      "  3. zoom_out (prob: 0.005, conf: 0.961)\n",
      "\n",
      "History: ['select', 'italic', 'underline']\n",
      "  1. font_size (prob: 0.520, conf: 0.987)\n",
      "  2. save (prob: 0.130, conf: 0.987)\n",
      "  3. insert_table (prob: 0.069, conf: 0.987)\n",
      "\n",
      "History: ['align_center']\n",
      "  1. align_left (prob: 0.278, conf: 0.124)\n",
      "  2. grammar_check (prob: 0.123, conf: 0.124)\n",
      "  3. select (prob: 0.106, conf: 0.124)\n",
      "\n",
      "History: ['font_size', 'font_family']\n",
      "  1. track_changes (prob: 0.411, conf: 0.969)\n",
      "  2. page_layout (prob: 0.156, conf: 0.969)\n",
      "  3. insert_header (prob: 0.109, conf: 0.969)\n",
      "\n",
      "History: ['new_document', 'save_as']\n",
      "  1. select (prob: 0.931, conf: 0.967)\n",
      "  2. print (prob: 0.025, conf: 0.967)\n",
      "  3. insert_image (prob: 0.013, conf: 0.967)\n",
      "\n",
      "History: ['open']\n",
      "  1. export_pdf (prob: 0.227, conf: 0.095)\n",
      "  2. find (prob: 0.147, conf: 0.095)\n",
      "  3. new_document (prob: 0.138, conf: 0.095)\n",
      "\n",
      "History: ['save', 'print']\n",
      "  1. page_layout (prob: 0.304, conf: 0.886)\n",
      "  2. new_document (prob: 0.207, conf: 0.886)\n",
      "  3. save_as (prob: 0.186, conf: 0.886)\n",
      "\n",
      "History: ['find', 'replace']\n",
      "  1. save (prob: 0.988, conf: 0.950)\n",
      "  2. insert_image (prob: 0.003, conf: 0.950)\n",
      "  3. print (prob: 0.002, conf: 0.950)\n",
      "\n",
      "History: ['insert_image', 'select']\n",
      "  1. zoom_out (prob: 0.997, conf: 0.984)\n",
      "  2. toggle_ruler (prob: 0.001, conf: 0.984)\n",
      "  3. cut (prob: 0.000, conf: 0.984)\n",
      "\n",
      "History: ['insert_table', 'insert_link']\n",
      "  1. select (prob: 0.870, conf: 0.942)\n",
      "  2. copy (prob: 0.051, conf: 0.942)\n",
      "  3. find (prob: 0.017, conf: 0.942)\n",
      "\n",
      "History: ['bullet_list', 'indent']\n",
      "  1. bullet_list (prob: 0.998, conf: 0.983)\n",
      "  2. outdent (prob: 0.001, conf: 0.983)\n",
      "  3. numbered_list (prob: 0.000, conf: 0.983)\n",
      "\n",
      "History: ['numbered_list', 'outdent']\n",
      "  1. grammar_check (prob: 0.983, conf: 0.991)\n",
      "  2. insert_table (prob: 0.004, conf: 0.991)\n",
      "  3. save (prob: 0.002, conf: 0.991)\n",
      "\n",
      "History: ['share_document', 'add_comment']\n",
      "  1. strike_through (prob: 0.727, conf: 0.318)\n",
      "  2. font_family (prob: 0.217, conf: 0.318)\n",
      "  3. share_document (prob: 0.012, conf: 0.318)\n",
      "\n",
      "History: ['track_changes', 'accept_change']\n",
      "  1. accept_change (prob: 0.990, conf: 0.973)\n",
      "  2. share_document (prob: 0.002, conf: 0.973)\n",
      "  3. reject_change (prob: 0.002, conf: 0.973)\n",
      "\n",
      "History: ['select', 'copy', 'paste', 'undo']\n",
      "  1. delete (prob: 0.520, conf: 0.997)\n",
      "  2. format_painter (prob: 0.184, conf: 0.997)\n",
      "  3. save (prob: 0.103, conf: 0.997)\n",
      "\n",
      "History: ['open', 'find', 'replace', 'save']\n",
      "  1. print (prob: 0.833, conf: 0.992)\n",
      "  2. export_pdf (prob: 0.091, conf: 0.992)\n",
      "  3. new_document (prob: 0.036, conf: 0.992)\n",
      "\n",
      "History: ['new_document', 'insert_header', 'insert_footer']\n",
      "  1. save_as (prob: 0.851, conf: 0.993)\n",
      "  2. insert_image (prob: 0.106, conf: 0.993)\n",
      "  3. save (prob: 0.015, conf: 0.993)\n",
      "\n",
      "History: ['save_as', 'export_pdf', 'share_document']\n",
      "  1. export_pdf (prob: 0.707, conf: 0.872)\n",
      "  2. format_painter (prob: 0.087, conf: 0.872)\n",
      "  3. insert_header (prob: 0.059, conf: 0.872)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict, Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ==== Configuration ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tool_vocab = [\n",
    "    # Basic Text Editing\n",
    "    \"cut\", \"copy\", \"paste\", \"select\", \"delete\", \"undo\", \"redo\",\n",
    "    \n",
    "    # Text Formatting\n",
    "    \"bold\", \"italic\", \"underline\", \"strike_through\", \"font_size\", \"font_family\", \"text_color\", \"highlight\",\n",
    "    \n",
    "    # Paragraph Formatting & Lists\n",
    "    \"align_left\", \"align_center\", \"align_right\", \"align_justify\",\n",
    "    \"indent\", \"outdent\", \"bullet_list\", \"numbered_list\", \"line_spacing\",\n",
    "    \n",
    "    # Document Management & Files\n",
    "    \"save\", \"save_as\", \"open\", \"new_document\", \"print\", \"export_pdf\",\n",
    "    \n",
    "    # Find & Replace\n",
    "    \"find\", \"replace\", \"find_and_replace_all\",\n",
    "    \n",
    "    # Insertions & Objects\n",
    "    \"insert_image\", \"insert_table\", \"insert_link\", \"insert_shape\", \"insert_chart\", \"insert_header\", \"insert_footer\",\n",
    "    \n",
    "    # View & Navigation\n",
    "    \"zoom_in\", \"zoom_out\", \"page_layout\", \"read_mode\", \"web_layout\",\n",
    "    \n",
    "    # Collaboration & Review\n",
    "    \"add_comment\", \"track_changes\", \"accept_change\", \"reject_change\", \"share_document\",\n",
    "    \n",
    "    # Other Utilities\n",
    "    \"format_painter\", \"spell_check\", \"grammar_check\", \"word_count\", \"toggle_ruler\"\n",
    "]\n",
    "\n",
    "tool_descriptions = {\n",
    "    # Basic Text Editing\n",
    "    \"cut\": \"removes selected content and places it in the clipboard, typically followed by paste\",\n",
    "    \"copy\": \"duplicates selected content to the clipboard without removing it, often followed by paste\",\n",
    "    \"paste\": \"inserts content from the clipboard at the current cursor position or replaces selected content\",\n",
    "    \"select\": \"highlights content (text, image, etc.) for further operation like cut, copy, delete, or formatting\",\n",
    "    \"delete\": \"removes content permanently; can often be undone\",\n",
    "    \"undo\": \"reverses the last action performed, crucial for correcting mistakes\",\n",
    "    \"redo\": \"re-applies a previously undone action, moving forward in the action history\",\n",
    "\n",
    "    # Text Formatting\n",
    "    \"bold\": \"applies bold formatting to selected text, making it stand out\",\n",
    "    \"italic\": \"applies italic formatting to selected text, often for emphasis or titles\",\n",
    "    \"underline\": \"applies an underline to selected text, commonly used for links or emphasis\",\n",
    "    \"strike_through\": \"draws a line through the middle of the selected text\",\n",
    "    \"font_size\": \"changes the size of the selected text\",\n",
    "    \"font_family\": \"changes the typeface or style of the selected text (e.g., Arial, Times New Roman)\",\n",
    "    \"text_color\": \"changes the color of the selected text\",\n",
    "    \"highlight\": \"applies a colored background to the selected text, like using a highlighter pen\",\n",
    "\n",
    "    # Paragraph Formatting & Lists\n",
    "    \"align_left\": \"aligns selected text or objects to the left margin\",\n",
    "    \"align_center\": \"centers selected text or objects horizontally on the page\",\n",
    "    \"align_right\": \"aligns selected text or objects to the right margin\",\n",
    "    \"align_justify\": \"aligns text to both the left and right margins, adding space between words as needed\",\n",
    "    \"indent\": \"increases the indentation of selected paragraphs or list items\",\n",
    "    \"outdent\": \"decreases the indentation of selected paragraphs or list items\",\n",
    "    \"bullet_list\": \"converts selected text into an unordered list with bullet points\",\n",
    "    \"numbered_list\": \"converts selected text into an ordered list with numbers\",\n",
    "    \"line_spacing\": \"adjusts the amount of vertical space between lines of text in a paragraph\",\n",
    "\n",
    "    # Document Management & Files\n",
    "    \"save\": \"stores the current state of the document to a file on disk\",\n",
    "    \"save_as\": \"saves the current document with a different name or location\",\n",
    "    \"open\": \"opens an existing document from a file\",\n",
    "    \"new_document\": \"creates a blank new document, usually starting a fresh project\",\n",
    "    \"print\": \"sends the current document to a printer for a hard copy\",\n",
    "    \"export_pdf\": \"saves the document in PDF format, commonly used for sharing final versions\",\n",
    "\n",
    "    # Find & Replace\n",
    "    \"find\": \"opens a dialog to search for specific text within the document\",\n",
    "    \"replace\": \"opens a dialog to find text and replace it with new text, often used after 'find'\",\n",
    "    \"find_and_replace_all\": \"finds all occurrences of text and replaces them automatically\",\n",
    "\n",
    "    # Insertions & Objects\n",
    "    \"insert_image\": \"adds an image from a file into the document\",\n",
    "    \"insert_table\": \"adds a structured grid of rows and columns to the document\",\n",
    "    \"insert_link\": \"creates a hyperlink to a web page or location within the document\",\n",
    "    \"insert_shape\": \"adds a geometric shape like a square or circle\",\n",
    "    \"insert_chart\": \"adds a data visualization from a spreadsheet or other source\",\n",
    "    \"insert_header\": \"adds content to the top margin of a document, appearing on every page\",\n",
    "    \"insert_footer\": \"adds content to the bottom margin of a document, appearing on every page\",\n",
    "\n",
    "    # View & Navigation\n",
    "    \"zoom_in\": \"magnifies the view of the document, making content appear larger\",\n",
    "    \"zoom_out\": \"reduces the magnification of the document, showing more content at once\",\n",
    "    \"page_layout\": \"changes the view to show how the document will look when printed\",\n",
    "    \"read_mode\": \"optimizes the view for reading, hiding toolbars and menus\",\n",
    "    \"web_layout\": \"shows the document as a web page, without page breaks\",\n",
    "\n",
    "    # Collaboration & Review\n",
    "    \"add_comment\": \"inserts a comment bubble attached to a specific piece of text, often for collaboration\",\n",
    "    \"track_changes\": \"activates a mode where all edits are marked for review\",\n",
    "    \"accept_change\": \"applies a tracked change permanently to the document\",\n",
    "    \"reject_change\": \"discards a tracked change, restoring the original text\",\n",
    "    \"share_document\": \"opens a dialog to share the document with other users for collaboration\",\n",
    "\n",
    "    # Other Utilities\n",
    "    \"format_painter\": \"copies formatting from one piece of content and applies it to another\",\n",
    "    \"spell_check\": \"initiates a check for spelling errors in the document\",\n",
    "    \"grammar_check\": \"initiates a check for grammatical errors in the document\",\n",
    "    \"word_count\": \"displays a count of words, characters, and pages in the document\",\n",
    "    \"toggle_ruler\": \"shows or hides the horizontal and vertical rulers\"\n",
    "}\n",
    "\n",
    "tool_patterns = {\n",
    "    # Basic Editing\n",
    "    \"cut\": [\"paste\", \"undo\", \"copy\", \"select\", \"save\"],\n",
    "    \"copy\": [\"paste\", \"undo\", \"select\", \"cut\"],\n",
    "    \"paste\": [\"undo\", \"select\", \"cut\", \"bold\", \"italic\", \"format_painter\"],\n",
    "    \"select\": [\"cut\", \"copy\", \"delete\", \"bold\", \"italic\", \"underline\", \"align_left\", \"format_painter\"],\n",
    "    \"delete\": [\"undo\", \"select\", \"cut\", \"save\"],\n",
    "    \"undo\": [\"redo\", \"cut\", \"copy\", \"paste\", \"delete\", \"save\"],\n",
    "    \"redo\": [\"undo\", \"paste\", \"select\", \"bold\", \"italic\"],\n",
    "    \"bold\": [\"italic\", \"underline\", \"select\", \"align_left\"],\n",
    "    \"italic\": [\"bold\", \"underline\", \"select\", \"align_center\"],\n",
    "    \"underline\": [\"bold\", \"italic\", \"select\", \"align_right\"],\n",
    "\n",
    "    # File Management\n",
    "    \"save\": [\"open\", \"new_document\", \"print\", \"export_pdf\"],\n",
    "    \"save_as\": [\"save\", \"open\", \"print\", \"share_document\"],\n",
    "    \"open\": [\"new_document\", \"save\"],\n",
    "    \"new_document\": [\"save\", \"open\", \"insert_table\", \"insert_image\"],\n",
    "    \"print\": [\"save\", \"new_document\", \"page_layout\"],\n",
    "    \"export_pdf\": [\"save\", \"share_document\"],\n",
    "\n",
    "    # Find & Replace\n",
    "    \"find\": [\"replace\", \"copy\", \"delete\", \"find_and_replace_all\"],\n",
    "    \"replace\": [\"find\", \"undo\", \"save\"],\n",
    "    \"find_and_replace_all\": [\"undo\", \"save\", \"find\"],\n",
    "\n",
    "    # Formatting and Lists\n",
    "    \"align_left\": [\"align_center\", \"align_right\", \"align_justify\", \"select\", \"indent\"],\n",
    "    \"align_center\": [\"align_left\", \"align_right\", \"align_justify\", \"select\"],\n",
    "    \"align_right\": [\"align_left\", \"align_center\", \"align_justify\", \"select\"],\n",
    "    \"align_justify\": [\"align_left\", \"align_center\", \"align_right\", \"select\"],\n",
    "    \"indent\": [\"outdent\", \"bullet_list\", \"numbered_list\"],\n",
    "    \"outdent\": [\"indent\", \"bullet_list\", \"numbered_list\"],\n",
    "    \"bullet_list\": [\"numbered_list\", \"indent\", \"outdent\", \"select\"],\n",
    "    \"numbered_list\": [\"bullet_list\", \"indent\", \"outdent\", \"select\"],\n",
    "    \"format_painter\": [\"select\", \"paste\", \"bold\", \"italic\"],\n",
    "    \"text_color\": [\"highlight\", \"select\", \"bold\"],\n",
    "    \"highlight\": [\"text_color\", \"select\"],\n",
    "\n",
    "    # Insertions\n",
    "    \"insert_image\": [\"select\", \"cut\", \"copy\", \"delete\"],\n",
    "    \"insert_table\": [\"select\", \"insert_link\", \"insert_chart\"],\n",
    "    \"insert_link\": [\"select\", \"copy\"],\n",
    "    \"insert_shape\": [\"select\", \"cut\", \"copy\", \"delete\"],\n",
    "    \"insert_chart\": [\"insert_table\", \"select\", \"cut\", \"copy\"],\n",
    "    \"insert_header\": [\"insert_footer\", \"page_layout\", \"insert_link\"],\n",
    "    \"insert_footer\": [\"insert_header\", \"page_layout\"],\n",
    "\n",
    "    # View & Navigation\n",
    "    \"zoom_in\": [\"zoom_out\", \"read_mode\", \"page_layout\"],\n",
    "    \"zoom_out\": [\"zoom_in\", \"page_layout\", \"web_layout\"],\n",
    "    \"read_mode\": [\"page_layout\", \"web_layout\", \"zoom_in\"],\n",
    "\n",
    "    # Collaboration\n",
    "    \"add_comment\": [\"share_document\", \"track_changes\", \"select\"],\n",
    "    \"track_changes\": [\"accept_change\", \"reject_change\", \"add_comment\", \"share_document\"],\n",
    "    \"accept_change\": [\"reject_change\", \"track_changes\", \"save\"],\n",
    "    \"reject_change\": [\"accept_change\", \"track_changes\"],\n",
    "    \"share_document\": [\"save\", \"add_comment\", \"export_pdf\"],\n",
    "    \n",
    "    # Utilities\n",
    "    \"spell_check\": [\"grammar_check\", \"undo\", \"save\"],\n",
    "    \"grammar_check\": [\"spell_check\", \"undo\", \"save\"],\n",
    "    \"word_count\": [\"save\", \"print\"],\n",
    "}\n",
    "\n",
    "pad_token_id = 0\n",
    "tool_to_id = {tool: idx + 1 for idx, tool in enumerate(tool_vocab)}\n",
    "id_to_tool = {idx + 1: tool for idx, tool in enumerate(tool_vocab)}\n",
    "vocab_size = len(tool_vocab) + 1\n",
    "context_len = 6  # Increased context length\n",
    "\n",
    "# ==== Enhanced Description Embeddings ====\n",
    "desc_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "desc_texts = [tool_descriptions[tool] for tool in tool_vocab]\n",
    "desc_embeddings = desc_model.encode(desc_texts, normalize_embeddings=True)\n",
    "desc_id_to_embedding = {\n",
    "    tool_to_id[tool]: torch.tensor(desc_embeddings[i], dtype=torch.float32).to(device)\n",
    "    for i, tool in enumerate(tool_vocab)\n",
    "}\n",
    "desc_dim = desc_embeddings.shape[1]\n",
    "\n",
    "# Add padding token embedding\n",
    "desc_id_to_embedding[pad_token_id] = torch.zeros(desc_dim, dtype=torch.float32).to(device)\n",
    "\n",
    "# ==== Enhanced Dataset with Pattern Mining ====\n",
    "class EnhancedToolDataset(Dataset):\n",
    "    def __init__(self, sequences, context_len, augment_data=True):\n",
    "        self.samples = []\n",
    "        self.pattern_freq = defaultdict(int)\n",
    "        self.context_len = context_len\n",
    "        \n",
    "        # First pass: collect pattern frequencies\n",
    "        for seq in sequences:\n",
    "            token_ids = [tool_to_id[t] for t in seq]\n",
    "            for i in range(1, len(token_ids)):\n",
    "                context = token_ids[max(0, i - context_len):i]\n",
    "                label = token_ids[i]\n",
    "                pattern = tuple(context[-min(3, len(context)):])  # Use last 3 tokens as pattern\n",
    "                self.pattern_freq[pattern] += 1\n",
    "        \n",
    "        # Second pass: create samples with weights\n",
    "        for seq in sequences:\n",
    "            token_ids = [tool_to_id[t] for t in seq]\n",
    "            for i in range(1, len(token_ids)):\n",
    "                context = token_ids[max(0, i - context_len):i]\n",
    "                label = token_ids[i]\n",
    "                context = [pad_token_id] * (context_len - len(context)) + context\n",
    "                \n",
    "                # Calculate sample weight based on pattern frequency\n",
    "                pattern = tuple(context[-min(3, len(context)):])\n",
    "                weight = 1.0 / (1 + self.pattern_freq[pattern] * 0.1)  # Reduce weight for common patterns\n",
    "                \n",
    "                self.samples.append((context, label, weight))\n",
    "        \n",
    "        # Data augmentation\n",
    "        if augment_data:\n",
    "            self._augment_data()\n",
    "    \n",
    "    def _augment_data(self):\n",
    "        \"\"\"Add synthetic samples based on known patterns\"\"\"\n",
    "        augmented_samples = []\n",
    "        for tool, likely_next in tool_patterns.items():\n",
    "            base_context = [pad_token_id] * (self.context_len - 1) + [tool_to_id[tool]]\n",
    "            for next_tool in likely_next:\n",
    "                augmented_samples.append((base_context, tool_to_id[next_tool], 0.5))\n",
    "        \n",
    "        self.samples.extend(augmented_samples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        context, label, weight = self.samples[idx]\n",
    "        return (torch.tensor(context, dtype=torch.long), \n",
    "                torch.tensor(label, dtype=torch.long),\n",
    "                torch.tensor(weight, dtype=torch.float32))\n",
    "\n",
    "# ==== Enhanced Model Architecture ====\n",
    "class EnhancedToolPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, desc_dim, n_heads, num_layers, context_len, desc_emb_table, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.context_len = context_len\n",
    "        self.desc_dim = desc_dim\n",
    "        \n",
    "        # Enhanced embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token_id)\n",
    "        self.pos_embedding = nn.Embedding(context_len, embed_dim)\n",
    "        self.desc_proj = nn.Linear(desc_dim, embed_dim)\n",
    "        self.desc_emb_table = desc_emb_table\n",
    "        \n",
    "        # Layer normalization for embeddings\n",
    "        self.embed_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Enhanced transformer with residual connections\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(\n",
    "                d_model=embed_dim, \n",
    "                nhead=n_heads, \n",
    "                dropout=dropout,\n",
    "                batch_first=True\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism for context weighting\n",
    "        self.context_attention = nn.MultiheadAttention(embed_dim, n_heads, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Multiple prediction heads\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "        self.confidence_head = nn.Linear(embed_dim, 1)  # Confidence scoring\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, std=0.02)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "        \n",
    "        # Token embeddings\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        \n",
    "        # Positional embeddings\n",
    "        pos_ids = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        \n",
    "        # Description embeddings\n",
    "        desc_emb = torch.stack([\n",
    "            torch.stack([\n",
    "                self.desc_proj(self.desc_emb_table.get(tok.item(), torch.zeros(self.desc_dim).to(x.device)))\n",
    "                for tok in row\n",
    "            ])\n",
    "            for row in x\n",
    "        ])\n",
    "        \n",
    "        # Combine embeddings\n",
    "        x_emb = tok_emb + pos_emb + desc_emb\n",
    "        x_emb = self.embed_norm(x_emb)\n",
    "        x_emb = self.dropout(x_emb)\n",
    "        \n",
    "        # Create causal mask\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        hidden = x_emb\n",
    "        for layer in self.transformer_layers:\n",
    "            hidden = layer(hidden, hidden, tgt_mask=tgt_mask)\n",
    "        \n",
    "        # Context attention for final representation\n",
    "        attn_out, _ = self.context_attention(hidden, hidden, hidden)\n",
    "        final_hidden = hidden + attn_out  # Residual connection\n",
    "        \n",
    "        # Use last token for prediction\n",
    "        last_hidden = final_hidden[:, -1, :]\n",
    "        \n",
    "        # Output predictions\n",
    "        logits = self.output_layer(last_hidden)\n",
    "        confidence = torch.sigmoid(self.confidence_head(last_hidden))\n",
    "        \n",
    "        return logits, confidence\n",
    "\n",
    "# ==== Enhanced Training with Focal Loss ====\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "def train_model(model, dataloader, epochs=100, lr=1e-3, save_path=\"best_model.pth\"):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    # Use focal loss for better handling of class imbalance\n",
    "    loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    confidence_loss_fn = nn.BCELoss()\n",
    "    \n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_data in dataloader:\n",
    "            context, label, weights = batch_data\n",
    "            context, label, weights = context.to(device), label.to(device), weights.to(device)\n",
    "            \n",
    "            logits, confidence = model(context)\n",
    "            \n",
    "            # Main prediction loss\n",
    "            pred_loss = loss_fn(logits, label)\n",
    "            \n",
    "            # Confidence loss (high confidence for correct predictions)\n",
    "            pred_correct = (torch.argmax(logits, dim=-1) == label).float()\n",
    "            conf_loss = confidence_loss_fn(confidence.squeeze(), pred_correct)\n",
    "            \n",
    "            # Weighted total loss\n",
    "            total_loss_batch = pred_loss + 0.1 * conf_loss\n",
    "            weighted_loss = (total_loss_batch * weights).mean()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            weighted_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += weighted_loss.item()\n",
    "            total_samples += len(context)\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            print(f\"Epoch {epoch+1}/{epochs}: New best model found with loss: {avg_loss:.4f}. Saving checkpoint...\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, save_path)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==== Enhanced Inference with Confidence ====\n",
    "def predict_next_with_confidence(model, history, top_k=3):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        context = [tool_to_id[t] for t in history][-context_len:]\n",
    "        context = [pad_token_id] * (context_len - len(context)) + context\n",
    "        context = torch.tensor([context], dtype=torch.long).to(device)\n",
    "        \n",
    "        logits, confidence = model(context)\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k, dim=-1)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(top_k):\n",
    "            tool_id = top_indices[0, i].item()\n",
    "            prob = top_probs[0, i].item()\n",
    "            conf = confidence[0, 0].item()\n",
    "            tool_name = id_to_tool.get(tool_id, \"<UNK>\")\n",
    "            predictions.append((tool_name, prob, conf))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# ==== Enhanced Data Generation ====\n",
    "def generate_realistic_sequences(tool_vocab, tool_patterns, num_sequences=200, min_len=3, max_len=8):\n",
    "    \"\"\"Generate more realistic tool usage sequences\"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    # Pattern-based generation\n",
    "    for _ in range(num_sequences // 2):\n",
    "        seq = []\n",
    "        current_tool = random.choice(tool_vocab)\n",
    "        seq.append(current_tool)\n",
    "        \n",
    "        length = random.randint(min_len, max_len)\n",
    "        for _ in range(length - 1):\n",
    "            if current_tool in tool_patterns:\n",
    "                # 70% chance to follow pattern, 30% random\n",
    "                if random.random() < 0.7:\n",
    "                    next_tool = random.choice(tool_patterns[current_tool])\n",
    "                else:\n",
    "                    next_tool = random.choice(tool_vocab)\n",
    "            else:\n",
    "                next_tool = random.choice(tool_vocab)\n",
    "            seq.append(next_tool)\n",
    "            current_tool = next_tool\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    \n",
    "    # Pure random generation\n",
    "    for _ in range(num_sequences // 2):\n",
    "        seq = random.choices(tool_vocab, k=random.randint(min_len, max_len))\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# ==== Common workflow patterns ====\n",
    "common_workflows = [\n",
    "    # 1. Drafting a New Document with Initial Formatting\n",
    "    # A user starts a new document, titles it, saves it, and adds initial text formatting.\n",
    "    [\"new_document\", \"save_as\", \"select\", \"bold\", \"font_size\", \"align_center\", \"insert_header\", \"save\"],\n",
    "\n",
    "    # 2. Editing and Reorganizing a Report Section\n",
    "    # The user opens a file, cuts a section, pastes it elsewhere, and then applies formatting.\n",
    "    [\"open\", \"select\", \"cut\", \"paste\", \"select\", \"align_justify\", \"line_spacing\", \"save\"],\n",
    "\n",
    "    # 3. Creating a List and Adjusting its Structure\n",
    "    # A user creates a bulleted list, adds a sub-list, and then changes it to a numbered list.\n",
    "    [\"select\", \"bullet_list\", \"indent\", \"numbered_list\", \"outdent\", \"save\"],\n",
    "\n",
    "    # 4. Finalizing a Document After Find & Replace\n",
    "    # The user performs a mass text replacement, then checks for errors before saving and exporting.\n",
    "    [\"find_and_replace_all\", \"undo\", \"spell_check\", \"grammar_check\", \"word_count\", \"save\", \"export_pdf\"],\n",
    "    \n",
    "    # 5. Reviewing a Collaborative Document\n",
    "    # A user opens a shared document, reviews changes, and adds a comment before sharing it again.\n",
    "    [\"share_document\", \"track_changes\", \"accept_change\", \"reject_change\", \"add_comment\", \"save\"],\n",
    "\n",
    "    # 6. Inserting and Formatting a Visual Element\n",
    "    # The user inserts an image, adjusts its size, and then adds a formatted caption.\n",
    "    [\"insert_image\", \"select\", \"zoom_out\", \"insert_link\", \"align_center\", \"save\"],\n",
    "    \n",
    "    # 7. Copying and Pasting Content with Formatting\n",
    "    # The user copies a formatted section, pastes it, and then uses the format painter to apply the style to a new section.\n",
    "    [\"select\", \"copy\", \"paste\", \"select\", \"format_painter\", \"paste\", \"undo\", \"save\"],\n",
    "    \n",
    "    # 8. Handling a File for Printing\n",
    "    # A user saves a document, adjusts the page layout, zooms in to review, and then sends it to the printer.\n",
    "    [\"save\", \"page_layout\", \"zoom_in\", \"zoom_out\", \"print\"],\n",
    "\n",
    "    [\"insert_table\", \"select\", \"paste\", \"bold\", \"align_center\", \"insert_link\", \"save\"],\n",
    "\n",
    "    # 10. Document Setup with Headers and Footers\n",
    "    # The user focuses on document structure, adding headers and footers with a page layout change.\n",
    "    [\"new_document\", \"page_layout\", \"insert_header\", \"insert_footer\", \"save_as\", \"print\"],\n",
    "    \n",
    "    # 11. Finalizing a Document with Error Checks\n",
    "    # A user performs a full review, correcting errors and checking word count before saving.\n",
    "    [\"open\", \"find\", \"spell_check\", \"grammar_check\", \"word_count\", \"save\", \"export_pdf\"],\n",
    "    \n",
    "    # 12. Working with Visuals and Shapes\n",
    "    # The user inserts a chart, then adds an explanatory shape and text to highlight a point.\n",
    "    [\"insert_chart\", \"insert_shape\", \"select\", \"add_comment\", \"save\"],\n",
    "    \n",
    "    # 13. Complex Text Formatting and Indentation\n",
    "    # The user formats a paragraph with a mix of tools before adjusting its indentation.\n",
    "    [\"select\", \"text_color\", \"highlight\", \"underline\", \"align_justify\", \"indent\", \"outdent\", \"save\"],\n",
    "    \n",
    "    # 14. Preparing a Document for Different View Modes\n",
    "    # The user adjusts the zoom and switches between view modes to review the document for different purposes.\n",
    "    [\"zoom_in\", \"zoom_out\", \"read_mode\", \"page_layout\", \"save\"],\n",
    "    \n",
    "    # 15. A User Reverting Multiple Actions\n",
    "    # The user makes a series of changes, then decides to revert them using multiple undo actions.\n",
    "    [\"cut\", \"paste\", \"bold\", \"delete\", \"undo\", \"undo\", \"undo\", \"save\"],\n",
    "\n",
    "    # 16. Applying a Consistent Format Across a Document\n",
    "    # A user selects text, formats it, and then repeatedly uses the format painter.\n",
    "    [\"select\", \"bold\", \"italic\", \"format_painter\", \"select\", \"format_painter\", \"select\", \"save\"],\n",
    "    \n",
    "    # 17. Creating Different Versions of a Document\n",
    "    # A user saves a document, then uses 'save as' to create a new version for a different purpose.\n",
    "    [\"open\", \"track_changes\", \"save\", \"save_as\", \"export_pdf\"],\n",
    "    \n",
    "    # 18. Inserting and Editing a Hyperlink\n",
    "    # The user selects text, adds a link, then revisits the link or its surrounding text.\n",
    "    [\"select\", \"insert_link\", \"select\", \"underline\", \"save\"],\n",
    "    \n",
    "    # 19. Formatting for Readability\n",
    "    # The user adjusts line spacing and text alignment for a paragraph.\n",
    "    [\"select\", \"line_spacing\", \"align_justify\", \"indent\", \"save\"],\n",
    "    \n",
    "    # 20. Starting a New, Complex Project\n",
    "    # A user begins a new project by inserting a header and a table, then saves the empty structure.\n",
    "    [\"new_document\", \"insert_header\", \"insert_table\", \"save_as\"],\n",
    "    \n",
    "    # 21. Fine-tuning Collaborative Changes\n",
    "    # The user is in review mode and selectively accepts and rejects changes.\n",
    "    [\"track_changes\", \"accept_change\", \"accept_change\", \"reject_change\", \"accept_change\", \"save\"],\n",
    "    \n",
    "    # 22. Navigating and Reviewing the Document View\n",
    "    # The user checks the document at different zoom levels and in different layouts.\n",
    "    [\"zoom_in\", \"page_layout\", \"zoom_out\", \"read_mode\", \"save\"],\n",
    "    \n",
    "    # 23. A User Changing Their Mind and Correcting\n",
    "    # A user formats a section, then deletes it and uses undo to retrieve it.\n",
    "    [\"select\", \"bold\", \"italic\", \"delete\", \"undo\", \"redo\", \"save\"],\n",
    "\n",
    "    # 24. A User Finding and Reusing Content\n",
    "    # The user finds a specific word, copies it, and pastes it elsewhere.\n",
    "    [\"find\", \"copy\", \"paste\", \"save\"],\n",
    "\n",
    "    # 25. A Quick File Conversion and Sharing Task\n",
    "    # The user opens a document and immediately exports it for sharing.\n",
    "    [\"open\", \"export_pdf\", \"share_document\"],\n",
    "\n",
    "    # 26. Building a Visual-Heavy Document\n",
    "    # The user inserts a sequence of different visual elements and then saves.\n",
    "    [\"new_document\", \"insert_image\", \"insert_shape\", \"insert_chart\", \"save\"],\n",
    "    \n",
    "    # 27. Correcting a List Hierarchy\n",
    "    # The user converts a bulleted list to a numbered list and adjusts indentation, then reverts part of it.\n",
    "    [\"select\", \"bullet_list\", \"indent\", \"numbered_list\", \"undo\", \"save\"],\n",
    "    \n",
    "    # 28. Simple Text Correction and Reformatting\n",
    "    # The user corrects a typo with delete/undo and then applies basic formatting.\n",
    "    [\"delete\", \"undo\", \"select\", \"bold\", \"save\"],\n",
    "\n",
    "    # 29. Fine-tuning Document Layout\n",
    "    # The user adjusts line spacing and switches between different layouts to see the impact.\n",
    "    [\"select\", \"line_spacing\", \"web_layout\", \"page_layout\", \"save\"],\n",
    "    \n",
    "    # 30. A User Performing a Quick Formatting Change\n",
    "    # A simple but common sequence where a user makes a quick, isolated change.\n",
    "    [\"select\", \"text_color\", \"save\"],\n",
    "]\n",
    "\n",
    "# ==== Enhanced Sample Data ====\n",
    "user_sequences = common_workflows * 3  # Repeat common patterns\n",
    "user_sequences += generate_realistic_sequences(tool_vocab, tool_patterns, 300)\n",
    "\n",
    "print(f\"Generated {len(user_sequences)} training sequences\")\n",
    "\n",
    "# ==== Run Enhanced Training ====\n",
    "dataset = EnhancedToolDataset(user_sequences, context_len, augment_data=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Training samples: {len(dataset)}\")\n",
    "\n",
    "model = EnhancedToolPredictor(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=128,  # Increased embedding dimension\n",
    "    desc_dim=desc_dim,\n",
    "    n_heads=8,  # More attention heads\n",
    "    num_layers=4,  # More layers\n",
    "    context_len=context_len,\n",
    "    desc_emb_table=desc_id_to_embedding,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {total_params:,}\")\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, dataloader, epochs=100, lr=2e-4)\n",
    "\n",
    "# ==== Enhanced Evaluation ====\n",
    "def evaluate_model(model, test_sequences):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for seq in test_sequences:\n",
    "            if len(seq) < 2:\n",
    "                continue\n",
    "            \n",
    "            for i in range(1, len(seq)):\n",
    "                history = seq[:i]\n",
    "                true_next = seq[i]\n",
    "                \n",
    "                predictions = predict_next_with_confidence(model, history, top_k=1)\n",
    "                predicted_tool = predictions[0][0]\n",
    "                \n",
    "                if predicted_tool == true_next:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Generate test sequences\n",
    "test_sequences = generate_realistic_sequences(tool_vocab, tool_patterns, 50, min_len=3, max_len=6)\n",
    "test_accuracy = evaluate_model(model, test_sequences)\n",
    "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "# ==== Enhanced Prediction Examples ====\n",
    "test_histories = [\n",
    "    # Basic editing patterns\n",
    "    [\"select\", \"copy\"],\n",
    "    [\"cut\", \"paste\"],\n",
    "    [\"select\", \"delete\"],\n",
    "    [\"undo\", \"undo\"],\n",
    "    \n",
    "    # Text formatting workflows\n",
    "    [\"select\", \"bold\"],\n",
    "    [\"select\", \"italic\", \"underline\"],\n",
    "    [\"align_center\"],\n",
    "    [\"font_size\", \"font_family\"],\n",
    "    \n",
    "    # Document management\n",
    "    [\"new_document\", \"save_as\"],\n",
    "    [\"open\"],\n",
    "    [\"save\", \"print\"],\n",
    "    \n",
    "    # Search and replace\n",
    "    [\"find\", \"replace\"],\n",
    "    \n",
    "    # Insertions\n",
    "    [\"insert_image\", \"select\"],\n",
    "    [\"insert_table\", \"insert_link\"],\n",
    "    \n",
    "    # Lists and formatting\n",
    "    [\"bullet_list\", \"indent\"],\n",
    "    [\"numbered_list\", \"outdent\"],\n",
    "    \n",
    "    # Collaboration and review\n",
    "    [\"share_document\", \"add_comment\"],\n",
    "    [\"track_changes\", \"accept_change\"],\n",
    "    \n",
    "    # Complex, multi-step sequences\n",
    "    [\"select\", \"copy\", \"paste\", \"undo\"],\n",
    "    [\"open\", \"find\", \"replace\", \"save\"],\n",
    "    [\"new_document\", \"insert_header\", \"insert_footer\"],\n",
    "    [\"save_as\", \"export_pdf\", \"share_document\"],\n",
    "]\n",
    "\n",
    "print(\"\\n=== Prediction Examples ===\")\n",
    "for history in test_histories:\n",
    "    predictions = predict_next_with_confidence(model, history, top_k=3)\n",
    "    print(f\"History: {history}\")\n",
    "    for i, (tool, prob, conf) in enumerate(predictions):\n",
    "        print(f\"  {i+1}. {tool} (prob: {prob:.3f}, conf: {conf:.3f})\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de14fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4a618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e427ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df86d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "import random \n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabfe44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configure device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare dataset\n",
    "tool_vocab = [\n",
    "    \"cut\", \"copy\", \"paste\", \"select\", \"delete\", \"undo\", \"redo\",\n",
    "    \"bold\", \"italic\", \"underline\", \"align_left\", \"align_center\", \"align_right\",\n",
    "    \"indent\", \"outdent\", \"bullet_list\", \"numbered_list\", \"find\", \"replace\",\n",
    "    \"save\", \"open\", \"new_document\", \"print\", \"zoom_in\", \"zoom_out\",\n",
    "    \"insert_image\", \"insert_table\", \"format_painter\"\n",
    "]\n",
    "tool_descriptions = {\n",
    "    \"cut\": \"removes the selected content and places it in the clipboard, typically followed by paste\",\n",
    "    \"copy\": \"duplicates the selected content to the clipboard without removing it, often followed by paste\",\n",
    "    \"paste\": \"inserts content from the clipboard at the current cursor position or replaces selected content\",\n",
    "    \"select\": \"highlights content (text, image, etc.) for further operation like cut, copy, delete, or formatting\",\n",
    "    \"delete\": \"removes content permanently without placing it in the clipboard; can often be undone\",\n",
    "    \"undo\": \"reverses the last action performed, crucial for correcting mistakes\",\n",
    "    \"redo\": \"re-applies a previously undone action, moving forward in the action history\",\n",
    "    \"bold\": \"applies bold formatting to selected text, making it stand out\",\n",
    "    \"italic\": \"applies italic formatting to selected text, often for emphasis or titles\",\n",
    "    \"underline\": \"applies an underline to selected text, commonly used for links or emphasis\",\n",
    "    \"align_left\": \"aligns selected text or objects to the left margin\",\n",
    "    \"align_center\": \"centers selected text or objects horizontally on the page\",\n",
    "    \"align_right\": \"aligns selected text or objects to the right margin\",\n",
    "    \"indent\": \"increases the indentation of selected paragraphs or list items, moving them further from the margin\",\n",
    "    \"outdent\": \"decreases the indentation of selected paragraphs or list items, moving them closer to the margin\",\n",
    "    \"bullet_list\": \"converts selected text into an unordered list with bullet points\",\n",
    "    \"numbered_list\": \"converts selected text into an ordered list with numbers\",\n",
    "    \"find\": \"opens a dialog to search for specific text within the document\",\n",
    "    \"replace\": \"opens a dialog to find text and replace it with new text, often used after 'find'\",\n",
    "    \"save\": \"stores the current state of the document to a file on disk\",\n",
    "    \"open\": \"opens an existing document from a file\",\n",
    "    \"new_document\": \"creates a blank new document, usually starting a fresh project\",\n",
    "    \"print\": \"sends the current document to a printer for a hard copy\",\n",
    "    \"zoom_in\": \"magnifies the view of the document, making content appear larger\",\n",
    "    \"zoom_out\": \"reduces the magnification of the document, showing more content at once\",\n",
    "    \"insert_image\": \"adds an image from a file into the document\",\n",
    "    \"insert_table\": \"adds a structured grid of rows and columns to the document\",\n",
    "    \"format_painter\": \"copies formatting from one piece of content and applies it to another\"\n",
    "}\n",
    "\n",
    "tool_patterns = {\n",
    "    \"cut\": [\"paste\", \"undo\", \"copy\", \"select\"],\n",
    "    \"copy\": [\"paste\", \"undo\", \"select\"],\n",
    "    \"paste\": [\"undo\", \"select\", \"cut\", \"format_painter\"],\n",
    "    \"select\": [\"cut\", \"copy\", \"delete\", \"bold\", \"italic\", \"underline\", \"align_left\", \"format_painter\"],\n",
    "    \"delete\": [\"undo\", \"select\", \"cut\"],\n",
    "    \"undo\": [\"redo\", \"cut\", \"copy\", \"paste\", \"delete\", \"save\"],\n",
    "    \"redo\": [\"undo\", \"paste\", \"select\", \"bold\", \"italic\"],\n",
    "    \"bold\": [\"italic\", \"underline\", \"select\", \"align_left\"],\n",
    "    \"italic\": [\"bold\", \"underline\", \"select\", \"align_center\"],\n",
    "    \"underline\": [\"bold\", \"italic\", \"select\", \"align_right\"],\n",
    "    \"align_left\": [\"align_center\", \"align_right\", \"select\"],\n",
    "    \"align_center\": [\"align_left\", \"align_right\", \"select\"],\n",
    "    \"align_right\": [\"align_left\", \"align_center\", \"select\"],\n",
    "    \"indent\": [\"outdent\", \"bullet_list\", \"numbered_list\"],\n",
    "    \"outdent\": [\"indent\", \"bullet_list\", \"numbered_list\"],\n",
    "    \"bullet_list\": [\"numbered_list\", \"indent\", \"outdent\", \"select\"],\n",
    "    \"numbered_list\": [\"bullet_list\", \"indent\", \"outdent\", \"select\"],\n",
    "    \"find\": [\"replace\", \"copy\", \"delete\"],\n",
    "    \"replace\": [\"find\", \"undo\", \"save\"],\n",
    "    \"save\": [\"new_document\", \"open\", \"print\"],\n",
    "    \"open\": [\"save\", \"new_document\", \"print\"],\n",
    "    \"new_document\": [\"save\"],\n",
    "    \"print\": [\"save\", \"new_document\", \"open\"],\n",
    "    \"zoom_in\": [\"zoom_out\"],\n",
    "    \"zoom_out\": [\"zoom_in\"],\n",
    "    \"insert_image\": [\"select\", \"delete\"],\n",
    "    \"insert_table\": [\"select\"],\n",
    "    \"format_painter\": [\"select\", \"paste\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521f61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\envs\\llm\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:408: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Padding token id\n",
    "pad_token_id = 0\n",
    "\n",
    "# Configation for data \n",
    "tool_to_id = {tool : idx+1 for idx, tool in enumerate(tool_vocab)}\n",
    "id_to_tool = {idx+1 : tool for idx, tool in enumerate(tool_vocab)}\n",
    "vocab_size = len(tool_vocab) + 1\n",
    "context_len = 6\n",
    "\n",
    "# Description Embeddings \n",
    "desc_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "desc_texts = [tool_descriptions[tool] for tool in tool_vocab]\n",
    "desc_embeddings = desc_model.encode(desc_texts, normalize_embeddings= True)\n",
    "desc_id_to_embedding = {\n",
    "    tool_to_id[tool] : torch.tensor(desc_embeddings[i], dtype= torch.float32).to(device) for i, tool in enumerate(tool_vocab)\n",
    "    }\n",
    "desc_emb = desc_embeddings.shape[1]\n",
    "\n",
    "# Add padding token embedding \n",
    "desc_id_to_embedding[pad_token_id] = torch.zeros(desc_emb, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d3021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolDataset(Dataset):\n",
    "    def __init__(self, sequences, context_len, augment_data=True):\n",
    "        super().__init__()\n",
    "        self.context_len = context_len\n",
    "        self.samples = []\n",
    "        self.pattern_freq = defaultdict(int)\n",
    "\n",
    "        # Collect pattern frequencies \n",
    "        for seq in sequences:\n",
    "            token_ids= [tool_to_id[tool] for tool in seq]\n",
    "            for i in range(1, len(token_ids)):\n",
    "                context = token_ids[max(i - context_len, 0):i]\n",
    "                label = token_ids[i]\n",
    "                pattern = tuple(context[-min(3, len(context)):])\n",
    "                self.pattern_freq[pattern] += 1\n",
    "\n",
    "        # Create samples with weights \n",
    "        for seq in sequences:\n",
    "            token_ids = [tool_to_id[tool] for tool in seq]\n",
    "            for i in range(1, len(token_ids)):\n",
    "                context = token_ids[max(0, i - context_len):i]\n",
    "                label = token_ids[i]\n",
    "                context = [pad_token_id] * (context_len - len(context)) + context\n",
    "\n",
    "                # Calculate weights based on sample frequency \n",
    "                pattern = tuple(context[-min(3, len(context)):])\n",
    "                weight = 1 / (1 + self.pattern_freq[pattern] * 0.1)\n",
    "\n",
    "                self.samples.append((context, label, weight))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        context, label, weight = self.samples[idx]\n",
    "        return (torch.tensor(context, dtype=torch.long),\n",
    "                torch.tensor(label, dtype=torch.long),\n",
    "                torch.tensor(weight, dtype=torch.float32))\n",
    "    \n",
    "class ToolPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, context_len, desc_dim, desc_emb_table, n_heads, num_layers, dropout=0.1):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.desc_dim = desc_dim\n",
    "        self.context_len = context_len\n",
    "\n",
    "        # Embeddings \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx= pad_token_id)\n",
    "        self.pos_embedding = nn.Embedding(context_len, embed_dim)\n",
    "        self.desc_proj = nn.Linear(desc_dim, embed_dim)\n",
    "        self.desc_emb_table = desc_emb_table\n",
    "\n",
    "        # Layer normalization \n",
    "        self.embed_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Transformer \n",
    "        self.transformer_layer = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(\n",
    "                d_model= embed_dim,\n",
    "                nhead= n_heads,\n",
    "                dropout= dropout,\n",
    "                batch_first= True\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Context Attention \n",
    "        self.context_attention = nn.MultiheadAttention(embed_dim= embed_dim, num_heads=n_heads, dropout= dropout, batch_first= True)\n",
    "\n",
    "        # Multiple prediction heads \n",
    "        self.output = nn.Linear(embed_dim, vocab_size)\n",
    "        self.confidence_head = nn.Linear(embed_dim, 1)\n",
    "\n",
    "        # Dropout regularization \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Initialize weights \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.normal_(module.weight, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        # Token embeddings \n",
    "        tok_emb = self.token_embedding(x)\n",
    "\n",
    "        # Positional Embeddings \n",
    "        pos_ids = torch.arange(seq_len, device= x.device).unsqueeze(0).expand(batch_size,-1)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "\n",
    "        # Description Embeddings \n",
    "        desc_emb = torch.stack([\n",
    "            torch.stack([\n",
    "                self.desc_proj(self.desc_emb_table.get(tok.item(), torch.zeros(self.desc_dim))) \n",
    "                for tok in row\n",
    "                ]) \n",
    "                for row in x\n",
    "            ])\n",
    "        \n",
    "        # Combine embeddings\n",
    "        x_emb = tok_emb + pos_emb + desc_emb\n",
    "\n",
    "        # Norm nad dropout\n",
    "        x_emb = self.embed_norm(x_emb)\n",
    "        self.dropout(x_emb)\n",
    "\n",
    "        # Causal Mask\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(x.device)\n",
    "\n",
    "        # Pass through transformer layer \n",
    "        hidden = x_emb\n",
    "        for layer in self.transformer_layer:\n",
    "            hidden= layer(hidden, hidden, tgt_mask= tgt_mask)\n",
    "\n",
    "        # Context attention for final representation \n",
    "        attn_out = self.context_attention(hidden, hidden, hidden)\n",
    "\n",
    "        # Final hidden layer\n",
    "        final_hidden = attn_out + hidden\n",
    "        \n",
    "        # Use last tokens for prediction\n",
    "        last_hidden = final_hidden[:,-1,:]\n",
    "\n",
    "        # Output\n",
    "        logits = self.output(last_hidden)\n",
    "        confidence= torch.sigmoid(self.confidence_head(last_hidden))\n",
    "\n",
    "        return logits, confidence\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b5e20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using focal loss as Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, dataloader, epochs=50, lr=1e-3):\n",
    "    optimizer= torch.optim.adamw(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "    # Use focal loss for better handling of class imbalance \n",
    "    loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "    confidence_loss_fn = nn.BCELoss()\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch_data in dataloader:\n",
    "            context, label, weights = batch_data\n",
    "            context, label, weights = context.to(device), label.to(device), weights.to(device)\n",
    "\n",
    "            logits, confidence = model(context)\n",
    "\n",
    "            # Prediction Loss \n",
    "            pred_loss = loss_fn(logits, label)\n",
    "\n",
    "            # Confidence Loss (high confidence for correct prediction)\n",
    "            pred_correct = \n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
